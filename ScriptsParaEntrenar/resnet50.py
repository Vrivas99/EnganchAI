# -*- coding: utf-8 -*-
"""Copy of EngagementModel.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OtqrxQOjtjeWoNTADRy0X8F85Yy5k2pz
"""

from google.colab import drive
import os
import tensorflow as tf

# Montar Google Drive
drive.mount('/content/drive')

# Cambiar directorio a la carpeta donde está tu archivo zip
os.chdir('/content/drive/My Drive/ImageModel')  # Cambia el directorio según tu ruta en Google Drive

# Verificar que el archivo zip esté presente
!ls

os.chdir('/content/drive/My Drive/ImageModel/NewCSVS')  # Cambia el directorio según tu ruta en Google Drive
!ls

import pandas as pd

# Cargar los CSVs
train_df = pd.read_csv('NewCSVS/train_Engagement_levels.csv')
validation_df = pd.read_csv('NewCSVS/validation_Engagement_levels.csv')
test_df = pd.read_csv('NewCSVS/test_Engagement_levels.csv')

# Mostrar un ejemplo de los DataFrames
print(train_df.head())

# Convertir la columna 'Engagement' a string
train_df['Engagement'] = train_df['Engagement'].astype(str)
validation_df['Engagement'] = validation_df['Engagement'].astype(str)
test_df['Engagement'] = test_df['Engagement'].astype(str)

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Definir los generadores de imágenes
train_datagen = ImageDataGenerator(rescale=1./255)
validation_datagen = ImageDataGenerator(rescale=1./255)

# Configurar los generadores para leer desde los CSVs
train_generator = train_datagen.flow_from_dataframe(
    dataframe=train_df,
    directory='NewCSVS',  # Carpeta donde están las imágenes
    x_col='FramePath',  # Columna con las rutas de las imágenes
    y_col='Engagement',  # Columna con las etiquetas (subclases)
    target_size=(224, 224),  # Tamaño de las imágenes de entrada (224x224 para ResNet50)
    class_mode='categorical',  # Usamos 'categorical' ya que son 4 subclases
    batch_size=8
)

validation_generator = validation_datagen.flow_from_dataframe(
    dataframe=validation_df,
    directory='NewCSVS',
    x_col='FramePath',
    y_col='Engagement',
    target_size=(224, 224),
    class_mode='categorical',
    batch_size=8
)

from tensorflow.keras.applications import ResNet50
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
from tensorflow.keras.optimizers import Adam

# Cargar el modelo base ResNet50 (sin las capas superiores)
base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Añadir capas personalizadas para la clasificación de 4 clases (0, 1, 2, 3 para Engagement)
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(1024, activation='relu')(x)
predictions = Dense(4, activation='softmax')(x)  # 4 clases para Engagement

# Definir el modelo completo
model = Model(inputs=base_model.input, outputs=predictions)

# Congelar las capas del modelo base para entrenar solo las nuevas capas
for layer in base_model.layers:
    layer.trainable = False

# Compilar el modelo
model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy',tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])

import os
import pandas as pd
from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger
from sklearn.metrics import precision_score, recall_score, f1_score
import tensorflow as tf
import numpy as np


# Configura los directorios para guardar los modelos y logs
model_save_dir = '/content/drive/MyDrive/ImageModel/Checkpoints/Engagement/'
csv_log_dir = '/content/drive/MyDrive/ImageModel/Logs/Engagement'

os.makedirs(model_save_dir, exist_ok=True)
os.makedirs(csv_log_dir, exist_ok=True)

# Definir el modelo (ejemplo: ResNet50)
# ... [Tu código para definir y compilar el modelo aquí]

# Configurar el ModelCheckpoint
checkpoint = ModelCheckpoint(
    os.path.join(model_save_dir, 'model_epoch_{epoch:02d}.keras'),
    save_freq='epoch',  # Guardar cada época
    save_best_only=False,  # Guardar independientemente de la calidad
    verbose=1
)

# Configurar el CSVLogger
csv_logger = CSVLogger(
    os.path.join(csv_log_dir, 'training_log.csv'),
    append=True,
    separator=','
)

# Definir una función personalizada para calcular métricas
def calculate_metrics(y_true, y_pred):
    precision = precision_score(y_true, y_pred, average='macro')
    recall = recall_score(y_true, y_pred, average='macro')
    f1 = f1_score(y_true, y_pred, average='macro')
    return precision, recall, f1

# Callback personalizado para calcular F1-Score
class F1ScoreCallback(tf.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs=None):
        precision = logs.get('precision', 0)
        recall = logs.get('recall', 0)

        # Calcular F1-Score
        if precision + recall > 0:
            f1_score = 2 * (precision * recall) / (precision + recall)
        else:
            f1_score = 0  # Para evitar división por cero

        logs['f1_score'] = f1_score
        print(f" — f1_score: {f1_score:.4f}")

# Obtener el último checkpoint guardado
checkpoints = [f for f in os.listdir(model_save_dir) if f.endswith('.keras')]
if checkpoints:
    latest_checkpoint = max(checkpoints, key=lambda x: int(x.split('_')[-1].split('.')[0]))  # Buscar el último por número de época
    latest_checkpoint_path = os.path.join(model_save_dir, latest_checkpoint)
    print(f"Cargando los pesos desde {latest_checkpoint_path}")
    model.load_weights(latest_checkpoint_path)
        # Extraer el número de época del nombre del checkpoint
    initial_epoch = int(latest_checkpoint.split('_')[-1].split('.')[0])
    print(f"Continuando el entrenamiento desde la época {initial_epoch + 1}")

else:
    print("No se encontraron checkpoints, comenzando desde cero.")
    initial_epoch = 0  # Comenzar desde la época 0

# Entrenar el modelo
model.fit(
    train_generator,
    epochs=100,
    validation_data=validation_generator,
    callbacks=[checkpoint, csv_logger, F1ScoreCallback()],initial_epoch=initial_epoch
)

# Generador para el conjunto de prueba
test_datagen = ImageDataGenerator(rescale=1./255)
test_generator = test_datagen.flow_from_dataframe(
    dataframe=test_df,
    directory='NewCSVS',
    x_col='FramePath',
    y_col='Engagement',
    target_size=(224, 224),
    class_mode='categorical',
    batch_size=32,
    shuffle=False
)

# Evaluar el modelo en el conjunto de prueba
evaluation = model.evaluate(test_generator)
print(f"Loss: {evaluation[0]}, Accuracy: {evaluation[1]}")